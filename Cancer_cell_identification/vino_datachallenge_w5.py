# -*- coding: utf-8 -*-
"""Vino_Datachallenge_W5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U9cniLfQLSyYhwZN5jddG_X8lvyIEzpG
"""

import pandas as pd
import matplotlib as plt
# %matplotlib inline
import numpy as np

from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc,recall_score,precision_score
import seaborn as sns
from google.colab import files

file = files.upload()

cols = ['ID','Clump Thickness', 
'Uniformity of Cell Size', 
'Uniformity of Cell Shape', 
'Marginal Adhesion', 
'Single Epithelial Cell Size', 
'Bare Nuclei',
'Bland Chromatin',
'Normal Nucleoli',
'Mitoses', 
'Class']#: (2 for benign, 4 for malignant)]

df = pd.read_csv('breast-cancer-wisconsin.csv',names = cols)

"""###EDA"""

df.info()

df = df.convert_objects(convert_numeric=True)

df = df.dropna()

df.head()

df.describe()

df1 = df

df = df.set_index("ID")

df.hist(bins=10,color='red', edgecolor='black', linewidth=1.0,
           xlabelsize=10, ylabelsize=10, grid=False,figsize=(15,15),layout = (5,2))
plt.xlabel = df["Class"]
plt.pyplot.savefig('Histogram_W5.png')

#files.download('Histogram_W5.png')

"""###Correlation Matrix"""

# calculate the correlation matrix
corr = df.corr()

# plot the heatmap
sns.heatmap(corr, 
        xticklabels=corr.columns, yticklabels=corr.columns)

"""From the above plot, we can infer that Mitosis has almost no correlation. For the sake of simplicity, we will not include Mitosis as a feature in the modelling. Since all other features have a higher than 0.6, we will include them in the modelling"""

df2 = df

y = df["Class"]

df = df.drop(["Mitoses","Class"],axis=1)

df.head()

"""###Modelling

Due to time constraint, I am doing a simple logistic regression and random forest classifier
"""

X_train, X_test, Y_train, Y_test = train_test_split(df,y, test_size = 0.2, random_state = 0)
model = LogisticRegression(random_state = 0)
model.fit(X_train, Y_train)

Y_pred = model.predict(X_test)
cm = confusion_matrix(Y_test, Y_pred)

sns.heatmap(cm, annot=True)

acc = (cm[0, 0] + cm[1, 1])/len(Y_test)
print('Accuracy is {:3.2f} %'.format(acc*100))

"""###Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier(random_state=0, n_estimators = 50, class_weight="balanced")
RF.fit(X_train, Y_train)
Y_pred = RF.predict(X_test)

cm = confusion_matrix(Y_test, Y_pred)

sns.heatmap(cm, annot=True)

acc = (cm[0, 0] + cm[1, 1])/len(Y_test)
print('Accuracy is {:3.2f} %'.format(acc*100))

"""Conclusions:

We find that random forest is better able to identify cancerous cells than Logistic regression. We can understand that from the fact that its low false positive rate and false negative rate compared to logistic regression
"""



